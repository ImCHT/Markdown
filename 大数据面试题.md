## 大数据面试题

### 策略

1. **分而治之/hash映射 + hash统计 + 堆/快速/归并排序。先映射后统计，最后排序。**
2. 多层划分
3. **Bloom filter/Bitmap；**
4. Trie树/数据库/倒排索引：数据量大，重复多，数据种类少，压缩实现
5. 外排序：归并方法，多路归并算法
6. 分布式处理之Hadoop/Mapreduce。

### 大数据数据中最大/最小的前k个数TopK

1. **全部排序**
   + 时间复杂度O(nlogn)
   + 需要将所有数据装入内存，内存很可能不够用
2. **局部淘汰法**
   + 时间复杂度O(nk)
   + 用一个容器（链表或数组）存储有序的K个数据，之后的数据不断读入，与容器中最小或最大的比较，符合条件的话就插入进入。遍历完数据之后，容器中的数就是TopK个数。
3. **分治法+堆/切分**
   - 将1亿个数据分成100份，每份100万个数据，找到每份数据中最大的10000个，最后在剩下的10010000个数据里面找出最大的10000个。如果100万数据选择足够理想，那么可以过滤掉1亿数据里面99%的数据。100万个数据里面查找最大的10000个数据的方法如下：**用快速排序切分的方法**，将数据分为2堆，如果大的那堆个数N大于10000个，继续对大堆快速排序一次分成2堆，如果大的那堆个数N大于10000个，继续对大堆快速排序一次分成2堆，如果大堆个数N小于10000个，就在小的那堆里面快速排序一次，找第10000-n大的数字；递归以上过程，就可以找到第1w大的数。参考上面的找出第1w大数字，就可以类似的方法找到前10000大数字了。此种方法需要每次的内存空间为10^64=4MB。一共需要进行
   - 这里进行分割时，需要保证每部分都选出k的最值。这样汇总之后才能保证topk个值在里面。
   - 对于多核或者多计算机可以采用分治法，提高速度
4. **哈希法**
   + 如果数据里面有很多重复的数据的话/数据范围比较小，可以先进行去重。然后通过分治法或最小堆法查找最大的10000个数。
5. **堆**
   + 时间复杂度O(nlogk)
   + 维持一个大小为K的最小堆（找最大的K个数），遍历数据，每个数和堆顶数据比较。如果比堆顶数据大的话，将堆顶数据替换成这个数，然后调整最小堆。遍历完数据之后，最小堆里的数据就是最大的K个数。
6. **切分函数**
   + 利用快速排序的分划函数找到分划位置K，则其前面的内容即为所求。该算法是一种非常有效的处理方式，时间复杂度是**O(N)**（证明可以参考算法导论书籍）。对于能一次加载到内存中的数组，该策略非常优秀。

### [分布式全局唯一ID](https://www.jianshu.com/p/9d7ebe37215e)

1. **是什么，作用，应用场景**

   在复杂分布式系统中，往往需要对大量的数据和消息进行唯一标识。如在美团点评的金融、支付、餐饮、酒店、猫眼电影等产品的系统中，数据日渐增长，对数据库的分库分表后需要有一个唯一ID来标识一条数据或消息，数据库的自增ID显然不能满足需求；特别一点的如订单、骑手、优惠券也都需要有唯一ID做标识。此时一个能够生成全局唯一ID的系统是非常必要的。

   要求：

   1.全局唯一性：不能出现重复的ID，最基本的要求。
   2.趋势递增：MySQL InnoDB引擎使用的是聚集索引，由于多数RDBMS使用B-tree的数据结构来存储索引数据，在主键的选择上面我们应尽量使用有序的主键保证写入性能。
   3.单调递增：保证下一个ID一定大于上一个ID。
   4.信息安全：如果ID是连续递增的，恶意用户就可以很容易的窥见订单号的规则，从而猜出下一个订单号，如果是竞争对手，就可以直接知道我们一天的订单量。所以在某些场景下，需要ID无规则。
   5.高可用，可用性达到5个9或4个9。
   6.高QPS，性能不能太差，否则容易造成线程堵塞。
   7.平均延迟和TP999(保证99.9%的请求都能成功的最低延迟)延迟都要尽可能低。

2. **实现方式**

   1. **UUID**

      UUID是指在一台机器在同一时间中生成的数字在所有机器中都是唯一的。按照开放软件基金会(OSF)制定的标准计算，用到了以太网卡地址、纳秒级时间、芯片ID码和许多可能的数字
       UUID由以下几部分的组合：
       （1）当前日期和时间。
       （2）时钟序列。
       （3）全局唯一的IEEE机器识别号，如果有网卡，从网卡MAC地址获得，没有网卡以其他方式获得。

      标准的UUID格式为：xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx **(8-4-4-4-12)**，以连字号分为五段形式的36个字符，示例：550e8400-e29b-41d4-a716-446655440000
       Java标准类库中已经提供了UUID的API。

      ```java
      UUID.randomUUID()
      ```

      **优点**

      - 性能非常高：本地生成，没有网络消耗。

      **缺点**

      - 不易存储：UUID太长，16字节128位，**通常以36长度的字符串**表示，很多场景不适用。
      - 信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。
      - ID作为主键时在特定的环境会存在一些问题，比如做DB主键的场景下，UUID就非常不适用。

   2. **SnowFlake雪花算法**

      雪花ID生成的是一个64位**(Long类型)**的二进制正整数，然后转换成10进制的数。64位二进制数由如下部分组成：

      ![](http://ww1.sinaimg.cn/mw690/005DF9Qily1g2cc3djomjj30qv05q74p.jpg)

      - **1位标识符**：始终是0，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0。
      -  **41位时间戳**：41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截 )得到的值，这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的。
      -  **10位机器标识码**：可以部署在1024个节点，如果机器分机房（IDC）部署，这10位可以由 **5位机房ID + 5位机器ID** 组成。
      -  **12位序列**：毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号

      **优点**

      - 简单高效，生成速度快。
      - 时间戳在高位，自增序列在低位，整个ID是趋势递增的，按照时间有序递增。
      - 灵活度高，可以根据业务需求，调整bit位的划分，满足不同的需求。

      **缺点**

      - 依赖机器的时钟，如果服务器时钟回拨，会导致重复ID生成。
      - 在分布式环境上，每个服务器的时钟不可能完全同步，有时会出现不是全局递增的情况。

   3. **数据库自增ID**

      主要思路是采用数据库自增ID + replace_into实现唯一ID的获取。

      ```sql
      create table t_global_id(
          id bigint(20) unsigned not null auto_increment,
          stub char(1) not null default '',
          primary key (id),
          unique key stub (stub)
      ) engine=MyISAM;
      
      # 每次业务可以使用以下SQL读写MySQL得到ID号
      replace into t_golbal_id(stub) values('a');
      select last_insert_id();
      ```

      replace into跟insert功能类似，不同点在于：replace into首先尝试插入数据列表中，如果发现表中已经有此行数据（根据主键或唯一索引判断）则先删除，再插入。否则直接插入新数据。
       当然为了避免数据库的单点故障，最少需要两个数据库实例，通过区分auto_increment的起始值和步长来生成奇偶数的ID。如下：

      ```sql
      Server1：
      auto-increment-increment = 2
      auto-increment-offset = 1
      
      Server2：
      auto-increment-increment = 2
      auto-increment-offset = 2
      ```

      **优点**

      - 简单。充分借助数据库的自增ID机制，可靠性高，生成有序的ID。

      **缺点**

      - ID生成依赖数据库单机的读写性能。
      - 依赖数据库，当数据库异常时整个系统不可用。

      **对于MySQL的性能问题，可以用如下方案解决**
       在分布式环境中，我们可以部署N台数据库实例，每台设置成不同的初始值，自增步长为机器的台数。每台的初始值分别为1,2,3...N，步长为N。

      ![](http://ww1.sinaimg.cn/mw690/005DF9Qily1g2ccqks1cvj30il0crmxd.jpg)

      以上方案虽然解决了性能问题，但是也存在很大的局限性：

      -  **系统水平扩容困难**：系统定义好步长之后，增加机器之后调整步长困难。如果要添加机器怎么办？假设现在只有一台机器发号是1,2,3,4,5（步长是1），这个时候需要扩容机器一台。可以这样做：把第二台机器的初始值设置得比第一台超过很多，比如14（假设在扩容时间之内第一台不可能发到14），同时设置步长为2，那么这台机器下发的号码都是14以后的偶数。然后摘掉第一台，把ID值保留为奇数，比如7，然后修改第一台的步长为2。让它符合我们定义的号段标准，对于这个例子来说就是让第一台以后只能产生奇数。扩容方案看起来复杂吗？貌似还好，现在想象一下如果我们线上有100台机器，这个时候要扩容该怎么做？简直是噩梦。
      -  **数据库压力大**：每次获取一个ID都必须读写一次数据库。当然对于这种问题，也有相应的解决方案，就是每次获取ID时都批量获取一个区间的号段到内存中，用完之后再来获取。数据库的性能提高了几个量级。

   4. **第三方软件生成**

      Redis实现了一个原子操作INCR和INCRBY实现递增的操作。当使用数据库性能不够时，可以采用Redis来代替，同时使用Redis集群来提高吞吐量。可以初始化每台Redis的初始值为1,2,3,4,5，然后步长为5。各个Redis生成的ID为：

      **优点**

      - 不依赖于数据库，灵活方便，且性能优于数据库。
      - 数字ID天然排序，对分页或者需要排序的结果很有帮助。

      **缺点：**

      - 如果系统中没有Redis，还需要引入新的组件，增加系统复杂度。
      - 需要编码和配置的工作量比较大。这个都不是最大的问题。

      关于分布式全局唯一ID的生成，各个互联网公司有很多实现方案，比如美团点评的Leaf-snowflake，用zookeeper解决了各个服务器时钟回拨的问题，弱依赖zookeeper。以及Leaf-segment类似上面数据库批量ID获取的方案。

### 大数据中出现频率最大TopK

+ 切分数据+hash统计+全排序。可以用hash取模映射到不同文件，相同文件取模后的哈希值也肯定一样。
+ 切分数据+hash统计+堆排序（大数据中数据最大/最小的前k个）

### 海量数据判重

1. 哈希表

   得解决哈希冲突，空间大

2. **布隆过滤器Bloom filter**

   位数组+k个独立的hash函数

   如何根据输入元素个数n，确定位数组m的大小及hash函数个数。当hash函数个数**k=(ln2)*(m/n)**时错误率最小。在错误率不大于E的情况下，m至少要等于n*lg(1/E)才能表示任意n个元素的集合。但m还应该更大些，因为还要保证bit数组里至少一半为0，则m应该>=nlg(1/E)*lge 大概就是**nlg(1/E)1.44**倍(lg表示以2为底的对数)。

   - [ ] 举个例子我们假设错误率为0.01，则此时m应大概是n的13倍。这样k大概是8个。算得不对啊

   m个文件的话，可以不用位数组，用counting Bloom filte（技术布隆过滤器），扫到最后一个文件，将计数值为m-1与这文件重复的取出来，即为m个文件重复的。

   应用场景：两个或多个文件中共同数据

   + 给你A,B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，让你找出A,B文件共同的URL。如果是三个乃至n个文件呢？

   缺点：有一定错误率

3. **位图BitMap**

   每个数据分配几位空间来表示数据的状态，如每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义。扫描两次文件。

   应用场景：

   + 在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数。
   + 给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？

   缺点：数据范围不能太大，数据范围需要可知

### 海量数据排序

1. 给定一个文件，里面最多含有n个不重复的正整数（也就是说可能含有少于n个不重复正整数），且其中每个数都小于等于n，n=10^7。得到按从小到大升序排列的包含所有输入的整数的列表。

   解题思路：

   1. 由于数据不重复，且数据范围知道，可以用位图进行排序。
      + 第一步，将所有的位都置为0，从而将集合初始化为空。
      + 第二步，通过读入文件中的每个整数来建立集合，将每个对应的位都置为1。
      + 第三步，检验每一位，如果该位为1，就输出对应的整数。
   2. 多路归并排序

### 多层划分

原理：因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。

适用范围：第k大，中位数，不重复或重复的数字

例子

1. 5亿个int找它们的中位数。

   解题思路：

   + 首先我们将int划分为2^16个区域，然后读取数据统计落到各个区域里的数的个数，之后我们根据统计结果就可以判断中位数落到那个区域，同时知道这个区域中的第几大数刚好是中位数。然后第二次扫描我们只统计落在这个区域中的那些数就可以了。

   + 具体：

     方法同基数排序有些像，开一个大小为65536的Int数组，第一遍读取，统计Int32的高16位的情况，也就是0-65535，都算作0,65536 - 131071都算作1。就相当于用该数除以65536。Int32 除以 65536的结果不会超过65536种情况，因此开一个长度为65536的数组计数就可以。每读取一个数，数组中对应的计数+1，考虑有负数的情况，需要将结果加32768后，记录在相应的数组内。

     第一遍统计之后，遍历数组，逐个累加统计，看中位数处于哪个区间，比如处于区间k，那么0- k-1的区间里数字的数量sum应该<n/2（2.5亿）。而k+1 - 65535的计数和也<n/2，第二遍统计同上面的方法类似，但这次只统计处于区间k的情况，也就是说(x / 65536) + 32768 = k。统计只统计低16位的情况。并且利用刚才统计的sum，比如sum = 2.49亿，那么现在就是要在低16位里面找100万个数(2.5亿-2.49亿)。这次计数之后，再统计一下，看中位数所处的区间，最后将高位和低位组合一下就是结果了。